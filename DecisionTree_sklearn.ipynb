{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5953c41-9cf1-475a-baa0-b265f3d2d6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /opt/anaconda3/envs/ML-Homework-1/bin/python\n",
      "Requirement already satisfied: pip in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (25.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (from scikit-learn) (2.3.2)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/ML-Homework-1/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.2-cp312-cp312-macosx_14_0_arm64.whl (20.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "# Run this cell in the same notebook where you saw the error\n",
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "\n",
    "# Install scikit-learn and commonly used libs (pandas, matplotlib)\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install scikit-learn pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a69dfbb2-5067-4e13-90c0-d7a47aa8b6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Iris dataset. Train size: 105, Test size: 45\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#  Q1: Use sklearn.tree.DecisionTreeClassifier on the Iris dataset\n",
    "# (loads data and creates a train/test split)\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# 30% test set, stratified to preserve class proportions\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Loaded Iris dataset. Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4c7a659-9147-473a-8ffa-4e9e55b13343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained DecisionTreeClassifier models for max_depth = [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Q2: Train trees with max_depth = 1, 2, 3\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "depths = [1, 2, 3]\n",
    "models = {}\n",
    "for d in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    models[d] = clf\n",
    "\n",
    "print(\"Trained DecisionTreeClassifier models for max_depth =\", depths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "681fc9fb-2963-4ca7-96f2-a0c4a1ebbe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test accuracies (rounded):\n",
      "           train_accuracy  test_accuracy\n",
      "max_depth                               \n",
      "1                  0.6667         0.6667\n",
      "2                  0.9714         0.8889\n",
      "3                  0.9810         0.9778\n"
     ]
    }
   ],
   "source": [
    "# Q3: Report training and test accuracy for each depth\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for d in sorted(models):\n",
    "    clf = models[d]\n",
    "    train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
    "    test_acc  = accuracy_score(y_test, clf.predict(X_test))\n",
    "    rows.append({\"max_depth\": d, \"train_accuracy\": train_acc, \"test_accuracy\": test_acc})\n",
    "\n",
    "results_df = pd.DataFrame(rows).sort_values(\"max_depth\").set_index(\"max_depth\")\n",
    "print(\"Train and Test accuracies (rounded):\")\n",
    "print(results_df.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e8253a4-d01d-47c5-8414-7ae4f71a3adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "max_depth = 1 | train = 0.6667 | test = 0.6667 | gap = 0.0000\n",
      "  → Diagnosis: UNDERFITTING (both train & test are low). Action: increase complexity / add features.\n",
      "\n",
      "max_depth = 2 | train = 0.9714 | test = 0.8889 | gap = 0.0825\n",
      "  → Diagnosis: GOOD FIT (train & test are both reasonably high and similar).\n",
      "\n",
      "max_depth = 3 | train = 0.9810 | test = 0.9778 | gap = 0.0032\n",
      "  → Diagnosis: GOOD FIT (train & test are both reasonably high and similar).\n"
     ]
    }
   ],
   "source": [
    "# Q4: signs of underfitting vs overfitting\n",
    "\"\"\"\n",
    "Signs of underfitting\n",
    "- Low train accuracy (model can't even fit training data).\n",
    "  Example: max_depth = 1 -> train ≈ 66.7%.\n",
    "- Train ≈ Test and both low. If both are low and close, the model has high bias\n",
    "  and is too simple.\n",
    "- Simple decision boundaries, high residual errors.\n",
    "- Learning curves: training and validation curves both low and close (flat, low\n",
    "  performance as data increases).\n",
    "\n",
    "Remedies for underfitting:\n",
    "- Increase model capacity (higher max_depth), add informative features,\n",
    "  remove excessive regularization, or use more expressive models.\n",
    "\n",
    "Signs of overfitting\n",
    "- Large positive gap: train accuracy ≫ test accuracy (e.g., train ~100%, test much lower).\n",
    "- High variance in cross-validation: large CV std or CV mean much lower than training score.\n",
    "- Learning curves: training score high, validation score low and not improving with more data.\n",
    "- Complex decision boundaries that conform to noise.\n",
    "\n",
    "Remedies for overfitting:\n",
    "- Reduce complexity (lower max_depth), prune the tree (ccp_alpha), increase\n",
    "  min_samples_leaf / min_samples_split.\n",
    "- Use cross-validation (GridSearchCV) to select hyperparameters.\n",
    "- Gather more data or use ensemble methods (RandomForest) to reduce variance.\n",
    "\n",
    "Signs of good fit (balanced)\n",
    "- High train and test accuracy and small gap (e.g., train ≈ test ≈ high).\n",
    "- Cross-validation mean ≈ train/test and low std.\n",
    "- Learning curves: both curves high and converging.\n",
    "\"\"\"\n",
    "\n",
    "for d in sorted(models):\n",
    "    clf = models[d]\n",
    "    train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
    "    test_acc  = accuracy_score(y_test, clf.predict(X_test))\n",
    "    gap = train_acc - test_acc  # positive => train > test\n",
    "\n",
    "    print(f\"\\nmax_depth = {d} | train = {train_acc:.4f} | test = {test_acc:.4f} | gap = {gap:.4f}\")\n",
    "    if train_acc < 0.80 and test_acc < 0.80:\n",
    "        print(\"  → Diagnosis: UNDERFITTING (both train & test are low). Action: increase complexity / add features.\")\n",
    "    elif gap > 0.10:\n",
    "        print(\"  → Diagnosis: OVERFITTING (train much higher than test). Action: prune, reduce max_depth, or increase min_samples_leaf.\")\n",
    "    else:\n",
    "        print(\"  → Diagnosis: GOOD FIT (train & test are both reasonably high and similar).\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbce8a-99c8-4741-ba51-dbeba318ca7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
